# Тонкая настройка ruBERT на задачу генерации бинарных ответов

Задача генерации ответа на общий вопрос сводится к бинарной классификации: у нас есть два класса (1 и 0), и входная последовательность (соединенный вопрос и текстовый фрагмент) может быть отнесена либо к одному, либо ко второму классу. Тонкая настройка осуществлялась с помощью класса Trainer из библиотеки huggingface. Была использована модель DeepPavlov/rubert-base-cased, архитектура модели – AutoModelForSequenceClassification. 

<ins>Гиперпараметры обучения:</ins>
* скорость обучения – 1e-5
* оптимизатор - AdamW
* warmup на первых 100 шагах обучения, далее последовательное уменьшение скорости с помощью линейного планировщика (англ. linear scheduler)
* количество эпох обучения – 5
* размер батча на обучении – 8
* размер батча на валидации – 8

Каждую эпоху вычислялась Accuracy, а также Precision, Recall и F1-мера для каждого класса. 

<ins>Результаты тонкой настройки ruBERT на исходном датасете:</ins>
* **Accuracy на валидации** = 0.52
* **Accuracy на тесте** = 0.503

|   | **Positive questions**  | **Negative Questions** |
|:-------------:|:-------------:|:-------------:
|Precision| 0.51  | 0.67  |
|Recall| 0.96  | 0.08 |
|F-1|0.67  | 0.14  |

Видно, что сильный дисбаланс классов в исходном датасете результирует в довольно низкие значения метрик именно для примеров с ответом "нет". Гипотеза, которая подтвердилась – добавление синтетических данных и приведение примеров двух классов к одинакомому числу позволяет повысить эти показатели, как и Accuracy. 

---

<ins>Результаты тонкой настройки ruBERT на расширенных обучающих данных (данные после генерации p-tuning-ом):</ins>

* **Accuracy на валидации** = 0.63 
* **Accuracy на тесте** = 0.523

|   | **Positive questions**  | **Negative Questions** |
|:-------------:|:-------------:|:-------------:
|Precision| 0.59  | 0.73  |
|Recall| 0.9  | 0.5 |
|F-1|75  | 62  |

---

<ins>Результаты тонкой настройки ruBERT на расширенных обучающих данных (данные после rule-based генерации):</ins>

* **Accuracy на валидации** = 0.6
* **Accuracy на тесте** = 0.522

|   | **Positive questions**  | **Negative Questions** |
|:-------------:|:-------------:|:-------------:
|Precision| 0.57  | 0.71  |
|Recall| 0.85  | 0.35 |
|F-1|0.68  | 0.47  |
