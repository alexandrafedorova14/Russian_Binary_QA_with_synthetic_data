# Тонкая настройка ruBERT на задачу генерации бинарных ответов

Задача генерации ответа на общий вопрос сводится к бинарной классификации: у нас есть два класса (1 и 0), и входная последовательность (соединенный вопрос и текстовый фрагмент) может быть отнесена либо к одному, либо ко второму классу. Тонкая настройка осуществлялась с помощью класса Trainer из библиотеки huggingface. Была использована модель DeepPavlov/rubert-base-cased, архитектура модели – AutoModelForSequenceClassification. 

<ins>Гиперпараметры обучения:</ins>
* скорость обучения – 1e-5
* оптимизатор - AdamW
* warmup на первых 100 шагах обучения, далее последовательное уменьшение скорости с помощью линейного планировщика (англ. linear scheduler)
* количество эпох обучения – 5
* размер батча на обучении – 8
* размер батча на валидации – 8

Каждую эпоху вычислялась Accuracy, а также Precision, Recall и F1-мера для каждого класса. 

<ins>Результаты тонкой настройки ruBERT на исходном датасете:</ins>
* **Accuracy на валидации** = 0.7
* **Accuracy на тесте** = 0.641

|   | **Positive questions**  | **Negative Questions** |
|:-------------:|:-------------:|:-------------:
|Precision| 0.64  | 0.83  |
|Recall| 0.9  | 0.5 |
|F-1|0.75  | 0.62  |


<ins>Результаты тонкой настройки ruBERT на расширенных обучающих данных (данные после генерации p-tuning-ом):</ins>

* **Accuracy на валидации** = 0.7
* **Accuracy на тесте** = 0.641

|   | **Positive questions**  | **Negative Questions** |
|:-------------:|:-------------:|:-------------:
|Precision| 0.64  | 0.83  |
|Recall| 0.9  | 0.5 |
|F-1|0.75  | 0.62  |
