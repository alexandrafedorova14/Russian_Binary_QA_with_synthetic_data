# Russian_Binary_QA_with_synthetic_data

Одной из задач NLU (Natural Language Understanding) является генерация ответов на вопрос (англ. question-answering). Ее частным случаем является генерация ответа на общий вопрос и отличается от классического question-answering тем, что от модели не требуется в прямом смысле извлечь ответ из соответствующего текстового фрагмента, а просто предсказать один из двух возможных ответов – "да" или "нет". Таким образом, задача генерации ответа на общие вопросы сводится к бинарной классификации.

В данной работе для решения этой задачи планируется использовать предобученную языковую модель, а именно моноязычную модель для русского языка ruBERT (Kuratov & Arkhipov, 2019). Задача решается следующим образом: на вход модели подаются обе последовательности – вопрос и текстовых фрагмент, к которому задан этот вопрос, – которые соединены специальным токеном [SEP]. Обе последовательности преобразуются в векторные представления или эмбеддинги (англ. embedding). Поскольку данная задача представляет собой текстовую классификацию, то на выходной слой подается эмбеддинг [CLS]. После применяется softmax и в результате каждая такая пара (вопрос-текстовый фрагмент) относится к одному из заданных классов, т.е. модель либо предсказывает ответ "да", либо "нет". 

На данный момент единственным датасетом общих вопросов на русском языке является DaNetQA (Glushkova et al., 2020), который включает в себя три набора данных – обучающую, валидационную и тестовую выборки, размеры которых составляют 1749, 821 и 805 триплетов вида "вопрос–текстовый фрагмент–ответ" соответственно. Размер обучающих данных довольно небольшой, поэтому достичь SOTA результата (Acc=91.5%) невозможно при тонкой настройке ruBERT на небольшом количестве эпох (в пределах 5). Возможным решением может стать генерация искуственных данных. Этот метод повышения качества вопросно-ответных моделей ранее уже предлагался в этой области, например в работах (Lewis et al. 2021) и (Bartolo et al., 2021). 

В данной работе генерация общих вопросов в русском осуществляется двумя способами: 
1. p-tuning ruGPT-3, поскольку для p-tuning-а в отличие от fine-tuning-а не требуется большого количества размеченных данных, а результаты сопоставимы. Для реализации используется библиотека ruPrompts
2. правиловая генерация вопросов, т.е. преобразование невопросительного предложения в вопросительное, а затем перефразирование получившихся вопросов с помощью нейросетевого рерайтера, чтобы добиться бóльшей синонимии и лексического разнообразия

После расширения обучающей выборки датасета решается непосредственно задача генерации ответа на вопрос, т.е. бинарная классификация. Поскольку в (Liu et al., 2021) было показано, что p-tuning дает результаты выше классической тонкой настройки, то в данной работе также помимо тонкой настройки применяется еще и p-tuning. Реализация p-tuning для класификации осуществляется с помощью библиотеки OpenPrompt. 
