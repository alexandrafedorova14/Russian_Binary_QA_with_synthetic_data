# Генерация общих вопросов с помощью p-tuning

Для реализации p-tuning для генерации была выбрана библиотека ([ruPrompts](https://github.com/ai-forever/ru-prompts)), в которой можно самостоятельно обучить подводку для выбранной NLP задачи. 
Шаблон подводки для генерации общих вопросов выглядит следующим образом: 
```<P*10>{answer}<P*10>{passage}<P*10>```

<b>NB</b> Вполне возможно, что и другое количество обучаемых токенов в подводке может также привести к хорошему качеству генерации, тем не менее, в данной работе экспериментальны путем было выбрано именно 30 обучаемых токенов. 

<ins>Гиперпараметры обучения:</ins>
* шагов обучения – 2500 
* скорость обучения – 0.1
* оптимизатор – AdamW
* warm-up на первых 500 шагах, затем постепенное понижение скорости обучения с помощью косинусного планировщика (англ. cosine scheduler)
* размер батча на обучении – 4
* размер батча на валидации – 2
* gradient_accumulation_steps – 4

<ins>Стратегии генерации для вопросов с ответом "да" и с ответом "нет" отличались:</ins>
1. Для генерации вопросов с ответом "да" использовался поиск по лучу (англ. beam search) с beam_size=3 и num_return_sequences=3. В качестве финального результата брался самый длинный вопрос. Также мы столкнулись с проблемой, которая заключалась в том, что при поиске по лучу вопросы почти всегда начинались с определенных слов, что приводило к достаточно однообразной структуре вопросов. Для того, чтобы это предотвратить, на половине примеров было сделано следующее: повторяющиеся токены были добавлены как `bad_words_ids`, поэтому при генерации они никогда не генерировались. Это позволило разнообразить вопросы в их структуре. Параметр температуры (англ. temperature) был выставлен 0.9 
2. Для генерации вопросов с ответом "нет" использовалось сэмплирование (англ. multinomial sampling), т.е. beam_size=1, do_sample=True, но num_return_sequences=3. Как и в случае с позитивными вопросами, из сгенерированных трех вариантов выбирался самый длинный. Параметр температуры (англ. temperature) был выставлен 0.9 

Всего было сгенерировано 5967 примеров, но в итоге в дальнейшей классификации использовалось чуть меньше, т.к. бралось меньше примеров с ответом "да", чтобы решить проблему сильно дисбаланса классов. 

Средняя перплексия (англ. perplexity) на сгенерированных данных – **14.2** 
