# P-tuning ruBERT под задачу генерации ответа на общий вопрос


Дополнительно обучение подводки или p-tuning было впервые предложенное в работе (Liu et al., 2021). В статье было показано, что метод позволяет достичь более высоких результатов для задачи генерации текста и задач на понимание текста, чем привычная тонкая настройка. Поэтому интересно сравнить результаты предсказаний ruBERT в задаче генерации ответа на вопрос после тонкой настройки и после дообучения подводки.  

<ins>Результаты p-tuning ruBERT на исходном датасете:</ins>
* **Accuracy на валидации** = 
* **Accuracy на тесте** = 

|   | **Positive questions**  | **Negative Questions** |
|:-------------:|:-------------:|:-------------:
|Precision|   |   |
|Recall|   |  |
|F-1|  |   |

---

<ins>Результаты p-tuning ruBERT на расширенном датасете (добавлены данные сгенерированные p-tuning-ом):</ins>
* **Accuracy на валидации** = 72.84
* **Accuracy на тесте** = 71.4

|   | **Positive questions**  | **Negative Questions** |
|:-------------:|:-------------:|:-------------:
|Precision| 67.21  | 84.19  |
|Recall| 89.56  | 55.99 |
|F-1|76.8  | 67.25  |

---

<ins>Результаты p-tuning ruBERT на расширенном датасете (добавлены данные сгенерированные rule-based алгоритмом):</ins>
* **Accuracy на валидации** = 70.52
* **Accuracy на тесте** = 67.1

|   | **Positive questions**  | **Negative Questions** |
|:-------------:|:-------------:|:-------------:
|Precision| 65.4  | 81.04  |
|Recall| 87.62  | 53.3 |
|F-1|74.9  | 64.31  |
